{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Few Shot Learning","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-07T01:14:14.458275Z","iopub.execute_input":"2025-08-07T01:14:14.458944Z","iopub.status.idle":"2025-08-07T01:14:21.004438Z","shell.execute_reply.started":"2025-08-07T01:14:14.458910Z","shell.execute_reply":"2025-08-07T01:14:21.002754Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load GPT-2 for text generation\n\ngenerator = pipeline('text-generation', model='gpt2')\nprompt = '''Summarize:\nInput: The cat sat on the mat.\nOutput: A cat sat down.\nInput: The dog barked loudly.\nOutput:'''\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T01:16:15.622655Z","iopub.execute_input":"2025-08-07T01:16:15.623002Z","iopub.status.idle":"2025-08-07T01:17:09.020344Z","shell.execute_reply.started":"2025-08-07T01:16:15.622975Z","shell.execute_reply":"2025-08-07T01:17:09.018841Z"}},"outputs":[{"name":"stderr","text":"2025-08-07 01:16:34.392022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754529394.786456      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754529394.885346      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1b596cf6ef84c9d9236e98d777b9ef4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"589708477cc34228ac7a43943bea8dda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"255685dad6dc4683b0c09d3ef17d68f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b40866bb44f441697058a0138cd2315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05334d6a920c499da20667475192874c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a67f76aea62848ecb4ef828b168843fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3718c05c0764a6da9fd15b8b1942244"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(generator(prompt, max_length=50)[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T01:17:09.022261Z","iopub.execute_input":"2025-08-07T01:17:09.022933Z","iopub.status.idle":"2025-08-07T01:17:22.866796Z","shell.execute_reply.started":"2025-08-07T01:17:09.022899Z","shell.execute_reply":"2025-08-07T01:17:22.865866Z"}},"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Summarize:\nInput: The cat sat on the mat.\nOutput: A cat sat down.\nInput: The dog barked loudly.\nOutput: A dog barked loudly.\nInput: The cat was screaming.\nOutput: A cat was screaming.\nInput: The cat was moving.\nOutput: A cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput: The cat was moving.\nInput\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Zero Shot Learning","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n# Load GPT-2 for text generation\ngenerator = pipeline('text-generation', model='gpt2')\n\nprompt = '''Translate the following sentence from English to French: 'Hello, how are you?'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T01:18:16.196037Z","iopub.execute_input":"2025-08-07T01:18:16.197100Z","iopub.status.idle":"2025-08-07T01:18:16.917755Z","shell.execute_reply.started":"2025-08-07T01:18:16.197063Z","shell.execute_reply":"2025-08-07T01:18:16.916431Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(generator(prompt, max_length=50)[0]['generated_text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-07T01:18:18.215242Z","iopub.execute_input":"2025-08-07T01:18:18.215585Z","iopub.status.idle":"2025-08-07T01:18:29.001598Z","shell.execute_reply.started":"2025-08-07T01:18:18.215561Z","shell.execute_reply":"2025-08-07T01:18:29.000454Z"}},"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nBoth `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","output_type":"stream"},{"name":"stdout","text":"Translate the following sentence from English to French: 'Hello, how are you? Welcome to the cafÃ©.'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you?'\n\n'Hello, how are you\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}